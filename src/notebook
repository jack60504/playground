curl https://api.groq.com/openai/v1/chat/completions \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $GROQ_API_KEY" \
-d '{
  "model": "llama3-groq-70b-8192-tool-use-preview",
  "messages": [
    {
      "role": "user",
      "content": "What'\''s the weather like in Boston today?"
    }
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "The city and state, e.g. San Francisco, CA"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"]
            }
          },
          "required": ["location"]
        }
      }
    }
  ],
  "tool_choice": "auto"
}'

import requests

api_url = "http://localhost:8000/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer YOUR_API_KEY"
}

messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "What is 1234 * 5678?"}
]

# Define the function the model can call
functions = [
    {
        "name": "calculate",
        "description": "Perform a basic arithmetic operation: add, subtract, multiply, divide two numbers",
        "parameters": {
            "type": "object",
            "properties": {
                "operation": {"type": "string", "enum": ["add", "subtract", "multiply", "divide"]},
                "num1": {"type": "number"},
                "num2": {"type": "number"}
            },
            "required": ["operation", "num1", "num2"]
        }
    }
]

payload = {
    "model": "llama3.1-70b-instruct",
    "messages": messages,
    "functions": functions,
    # Encouraging the model to call the function if it can't directly answer
    "function_call": "auto"
}

response = requests.post(api_url, headers=headers, json=payload)
result = response.json()

print(result)

docker run -d -p 3000:8080 \
-v open-webui:/app/backend/data \
-e OPENAI_API_BASE_URLS="https://your-openai-endpoint.com/v1" \
-e OPENAI_API_KEYS="your_openai_api_key" \
--name open-webui \
--restart always \
ghcr.io/open-webui/open-webui:main


